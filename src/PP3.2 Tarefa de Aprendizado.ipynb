{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "H8mGuzlhvlUU"
   },
   "outputs": [],
   "source": [
    "# bibliotecas\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Subset, DataLoader, ConcatDataset, random_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold, train_test_split\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SyPDZvkoDYpX"
   },
   "source": [
    "## Escolha da Tarefa de Aprendizado\n",
    "\n",
    "A tarefa de aprendizado de máquina definida neste trabalho é a classificação de imagens binária, com o objetivo de identificar se uma imagem é real (fotografia de pessoas reais) ou sintética, ou seja, gerada por Inteligência Artificial. Como se trata de um problema visual e a tarefa envolve reconhecer padrões sutis na textura, iluminação e traços que podem diferenciar uma imagem real de uma sintética, optamos por utilizar uma Rede Neural Convolucional (CNN), que é uma arquitetura especialmente eficaz para extração automática de características em tarefas de classificação de imagens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHgIsnlc3J-x"
   },
   "source": [
    "### Carregamento e Pré-Processamento do Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HdW7JJ--0sRd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 files belonging to 2 classes.\n",
      "Found 20000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from utils import data_utils_keras\n",
    "\n",
    "train_data, test_data = data_utils_keras.load_and_preprocess_data_tf(resize_to=(32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXt9nU5q290R"
   },
   "source": [
    "### Divisão Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P0Ji5SoJ5RmD",
    "outputId": "c7c6b00c-940c-46cb-8be8-b6b9df6a6ceb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 50000, 1: 50000})\n"
     ]
    }
   ],
   "source": [
    "all_labels = []\n",
    "for _, labels in train_data:  # train_data é tf.data.Dataset\n",
    "    all_labels.extend(labels.numpy().tolist())  # converte tensores para lista\n",
    "\n",
    "label_counts = Counter(all_labels)\n",
    "print(label_counts)  # ex: Counter({0: 3125, 1: 3125})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JU9EZmJW5f9i",
    "outputId": "cfbbfb57-b6bf-4395-bd1e-56af48fed325"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 files belonging to 2 classes.\n",
      "Classes: ['FAKE', 'REAL']\n"
     ]
    }
   ],
   "source": [
    "# Caminho dos datasets\n",
    "train_dir = '../data/train'\n",
    "\n",
    "# Carrega dataset original para poder acessar .class_names depois\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=True,\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "# Classes (ordem baseada na alfabética das pastas)\n",
    "print(\"Classes:\", train_ds.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_yrAe7_X0LS"
   },
   "source": [
    "O conjunto de dados de treino já está balanceado, contendo 50.000 imagens reais (classe 1) e 50.000 imagens geradas por IA (classe 0). Isso significa que o modelo será treinado com a mesma quantidade de exemplos para cada classe, o que ajuda a evitar viés de aprendizado. Com esse equilíbrio, a CNN tem maiores chances de aprender a distinguir padrões relevantes de cada classe de forma justa, sem favorecer uma categoria em detrimento da outra, o que pode resultar em melhor desempenho e métricas mais confiáveis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9LRVObh_9Rm6"
   },
   "source": [
    "Neste trabalho, optamos por utilizar a validação do tipo holdout estratificado, dividindo o conjunto de dados em 70% para treino, 15% para validação e 15% para teste. Embora a validação cruzada k-fold ofereça uma avaliação mais robusta por repetir o treinamento múltiplas vezes com diferentes divisões dos dados, ela também apresenta um custo computacional significativamente maior, especialmente quando se utiliza CNNs e um volume elevado de dados, como no caso deste projeto. O holdout, por sua vez, permite uma separação mais simples e rápida, com desempenho adequado quando há uma boa quantidade de dados e as classes estão balanceadas. Por isso, a escolha pelo holdout foi feita visando um equilíbrio entre qualidade de avaliação e viabilidade computacional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "hESJdappA1hy"
   },
   "outputs": [],
   "source": [
    "all_labels = np.array(all_labels)\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "train_idx, val_idx = next(split.split(np.zeros(len(all_labels)), all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "Gt4QMw20BFsL"
   },
   "outputs": [],
   "source": [
    "train_split = Subset(train_data, train_idx)\n",
    "val_split = Subset(train_data, val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3dqYVZurBKc-",
    "outputId": "abcc8eab-e7f5-48e7-8276-b8afe804a0cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino:    70000 imagens\n",
      "Validação: 30000 imagens\n",
      "Teste:     625 imagens\n"
     ]
    }
   ],
   "source": [
    "print(f\"Treino:    {len(train_split)} imagens\")\n",
    "print(f\"Validação: {len(val_split)} imagens\")\n",
    "print(f\"Teste:     {len(test_data)} imagens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(dataset):\n",
    "    X = []\n",
    "    y = []\n",
    "    for img, label in dataset:\n",
    "        X.append(img.numpy())  \n",
    "        y.append(label)\n",
    "    X = np.stack(X)\n",
    "    y = np.array(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_X_y(train_split.dataset)\n",
    "X_val, y_val = get_X_y(val_split.dataset)\n",
    "X_test, y_test = get_X_y(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a avaliação de desempenho do modelo foi escolhido as métricas: acurácia, F1-score macro, matriz de confusão e curva de aprendizado.\n",
    "\n",
    "- Acurácia\n",
    "\n",
    "Uma métrica fundamental para avaliar modelos de classificação, especialmente quando as classes estão balanceadas, como é o caso do dataset utilizado. \n",
    "\n",
    "- F1-Score Macro \n",
    "\n",
    "É importante pois ele calcula a média do F1-Score para cada classe, tratando todas com igual importância, também leva em conta tanto a precisão quanto a revocação, sendo mais robusto em problemas de classificação binária.\n",
    "\n",
    "- Matriz de confusão \n",
    "\n",
    "É essencial para entender como o modelo está errando, mostrando os falsos positivos e falsos negativos. Além disso, permite uma análise mais profunda do comportamento do modelo em relação a cada classe.\n",
    "\n",
    "- Curva de aprendizado \n",
    "\n",
    "É um recurso visual que ajuda a diagnosticar problemas de overfitting ou underfitting. Monitorar a evolução da loss e da acurácia no conjunto de treinamento e validação ao longo das épocas é uma prática essencial no desenvolvimento de CNNs.\n",
    "\n",
    "- AUC-ROC\n",
    "\n",
    "A Área sob a Curva ROC é uma métrica que avalia a capacidade do modelo em distinguir entre as classes. Um valor de AUC próximo de 1 indica uma excelente capacidade discriminativa, enquanto um valor próximo de 0.5 sugere que o modelo está performando de forma semelhante ao acaso."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "cifake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
