{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H8mGuzlhvlUU"
      },
      "outputs": [],
      "source": [
        "# bibliotecas\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Subset, DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "import kagglehub\n",
        "from collections import Counter\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import random_split, Subset\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyPDZvkoDYpX"
      },
      "source": [
        "## Escolha da Tarefa de Aprendizado\n",
        "\n",
        "A tarefa de aprendizado de máquina definida neste trabalho é a classificação de imagens binária, com o objetivo de identificar se uma imagem é real (fotografia de pessoas reais) ou sintética, ou seja, gerada por Inteligência Artificial. Como se trata de um problema visual e a tarefa envolve reconhecer padrões sutis na textura, iluminação e traços que podem diferenciar uma imagem real de uma sintética, optamos por utilizar uma Rede Neural Convolucional (CNN), que é uma arquitetura especialmente eficaz para extração automática de características em tarefas de classificação de imagens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHgIsnlc3J-x"
      },
      "source": [
        "### Leitura do dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "A8liFucq0ywf"
      },
      "outputs": [],
      "source": [
        "path = kagglehub.dataset_download(\"birdy654/cifake-real-and-ai-generated-synthetic-images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdW7JJ--0sRd"
      },
      "outputs": [],
      "source": [
        "train_path = f\"{path}/cifake/train\"\n",
        "test_path = f\"{path}/cifake/test\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pré-processamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAZ77o-Q1KLR"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_data = datasets.ImageFolder(root=\"../data/train\", transform=transform)\n",
        "test_data = datasets.ImageFolder(root=\"../data/test\", transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXt9nU5q290R"
      },
      "source": [
        "### Divisão Holdout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0Ji5SoJ5RmD",
        "outputId": "c7c6b00c-940c-46cb-8be8-b6b9df6a6ceb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({0: 50000, 1: 50000})"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_labels = train_data.targets\n",
        "train_label_counts = Counter(train_labels)\n",
        "train_label_counts # 0: FAKE / 1: REAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JU9EZmJW5f9i",
        "outputId": "cfbbfb57-b6bf-4395-bd1e-56af48fed325"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['FAKE', 'REAL']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_yrAe7_X0LS"
      },
      "source": [
        "O conjunto de dados de treino já está balanceado, contendo 50.000 imagens reais (classe 1) e 50.000 imagens geradas por IA (classe 0). Isso significa que o modelo será treinado com a mesma quantidade de exemplos para cada classe, o que ajuda a evitar viés de aprendizado. Com esse equilíbrio, a CNN tem maiores chances de aprender a distinguir padrões relevantes de cada classe de forma justa, sem favorecer uma categoria em detrimento da outra, o que pode resultar em melhor desempenho e métricas mais confiáveis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LRVObh_9Rm6"
      },
      "source": [
        "Neste trabalho, optamos por utilizar a validação do tipo holdout estratificado, dividindo o conjunto de dados em 70% para treino, 15% para validação e 15% para teste. Embora a validação cruzada k-fold ofereça uma avaliação mais robusta por repetir o treinamento múltiplas vezes com diferentes divisões dos dados, ela também apresenta um custo computacional significativamente maior, especialmente quando se utiliza CNNs e um volume elevado de dados, como no caso deste projeto. O holdout, por sua vez, permite uma separação mais simples e rápida, com desempenho adequado quando há uma boa quantidade de dados e as classes estão balanceadas. Por isso, a escolha pelo holdout foi feita visando um equilíbrio entre qualidade de avaliação e viabilidade computacional."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kLesTrbV1waj"
      },
      "outputs": [],
      "source": [
        "train_labels = train_data.targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hESJdappA1hy"
      },
      "outputs": [],
      "source": [
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
        "train_idx, val_idx = next(split.split(np.zeros(len(train_labels)), train_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Gt4QMw20BFsL"
      },
      "outputs": [],
      "source": [
        "train_split = Subset(train_data, train_idx)\n",
        "val_split = Subset(train_data, val_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dqYVZurBKc-",
        "outputId": "abcc8eab-e7f5-48e7-8276-b8afe804a0cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Treino: 70000 imagens\n",
            "Validação: 30000 imagens\n",
            "Teste: 20000 imagens\n"
          ]
        }
      ],
      "source": [
        "print(f\"Treino: {len(train_split)} imagens\")\n",
        "print(f\"Validação: {len(val_split)} imagens\")\n",
        "print(f\"Teste: {len(test_data)} imagens\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
