{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "H8mGuzlhvlUU"
   },
   "outputs": [],
   "source": [
    "# bibliotecas\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHgIsnlc3J-x"
   },
   "source": [
    "### Carregamento e Pré-Processamento do Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "A8liFucq0ywf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 files belonging to 2 classes.\n",
      "Found 20000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from utils.data_utils_keras import load_and_preprocess_data_tf, ModelType\n",
    "\n",
    "batch_size = 32\n",
    "image_size = (224, 224)\n",
    "train_ds, test_ds = load_and_preprocess_data_tf(resize_to=image_size,\n",
    "                                                batch_size=batch_size,\n",
    "                                                model_type=ModelType.RESNET50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXt9nU5q290R"
   },
   "source": [
    "### Divisão Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hESJdappA1hy"
   },
   "outputs": [],
   "source": [
    "total_batches = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "total_samples = total_batches * batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Gt4QMw20BFsL"
   },
   "outputs": [],
   "source": [
    "# Define proporção de treino (70%) e validação (30%) usando o número de batches\n",
    "train_batches = int(total_batches * 0.7)\n",
    "val_batches = total_batches - train_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3dqYVZurBKc-",
    "outputId": "abcc8eab-e7f5-48e7-8276-b8afe804a0cc"
   },
   "outputs": [],
   "source": [
    "# Embaralha os batches do dataset\n",
    "train_ds_shuffled = train_ds.shuffle(buffer_size=1000, seed=42, reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão trenio e validação\n",
    "train_ds = train_ds_shuffled.take(train_batches)\n",
    "val_ds = train_ds_shuffled.skip(train_batches)\n",
    "\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches de treino: 2187\n",
      "Batches de validação: 938\n",
      "Aproximadamente 69984 amostras de treino\n",
      "Aproximadamente 30016 amostras de validação\n"
     ]
    }
   ],
   "source": [
    "print(f\"Batches de treino: {train_batches}\")\n",
    "print(f\"Batches de validação: {val_batches}\")\n",
    "print(f\"Aproximadamente {train_batches * batch_size} amostras de treino\")\n",
    "print(f\"Aproximadamente {val_batches * batch_size} amostras de validação\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo\n",
    "\n",
    "**ResNet50**\n",
    "\n",
    "O ResNet50 é uma arquitetura de rede neural convolucional profunda de ponta, desenvolvida pela Microsoft Research em 2015. É uma variante da popular arquitetura ResNet e compreende 50 camadas que permitem o aprendizado de arquiteturas muito mais profundas do que era possível anteriormente, sem o problema de gradientes que desaparecem. \n",
    "\n",
    "A arquitetura do ResNet50 é dividida em quatro partes principais: as camadas convolucionais, o bloco de identidade, o bloco convolucional e as camadas totalmente conectadas. As camadas convolucionais são responsáveis ​​por extrair características da imagem de entrada, o bloco de identidade e o bloco convolucional processam e transformam essas características, e as camadas totalmente conectadas fazem a classificação final. O ResNet50 foi treinado no grande conjunto de dados ImageNet, alcançando uma taxa de erro equivalente ao desempenho humano, tornando-o um modelo poderoso para diversas tarefas de classificação de imagens, como detecção de objetos, reconhecimento facial e análise de imagens médicas. Além disso, também tem sido usado como um extrator de características para outras tarefas, como detecção de objetos e segmentação semântica.\n",
    "\n",
    "Fonte: https://medium.com/@nitishkundu1993/exploring-resnet50-an-in-depth-look-at-the-model-architecture-and-code-implementation-d8d8fa67e46f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"GPU\" if len(tf.config.list_physical_devices(\"GPU\")) > 0 else \"CPU\"\n",
    "print(f\"Usando: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(*image_size, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = model.predict(test_ds)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int).ravel()\n",
    "\n",
    "# Extrair labels verdadeiros do dataset de teste\n",
    "y_test = []\n",
    "for _, labels in test_ds:\n",
    "    y_test.extend(labels.numpy())\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Flatten y_pred_prob para garantir formato correto\n",
    "y_pred_prob = y_pred_prob.ravel()\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\n",
    "plt.xlabel(\"Predito\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.title(\"Matriz de Confusão\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Real\", \"Fake\"]))\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "print(f\"AUC (ROC): {roc_auc:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "# Acurácia\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Treino')\n",
    "plt.plot(history.history['val_accuracy'], label='Validação')\n",
    "plt.title(\"Curva de Aprendizado - Acurácia\")\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Acurácia\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Perda\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Treino')\n",
    "plt.plot(history.history['val_loss'], label='Validação')\n",
    "plt.title(\"Curva de Aprendizado - Perda\")\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Perda (Loss)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
