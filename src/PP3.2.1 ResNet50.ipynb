{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8mGuzlhvlUU"
      },
      "outputs": [],
      "source": [
        "# bibliotecas\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Subset, DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "import kagglehub\n",
        "from collections import Counter\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import random_split, Subset\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHgIsnlc3J-x"
      },
      "source": [
        "### Leitura do dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "A8liFucq0ywf"
      },
      "outputs": [],
      "source": [
        "path = kagglehub.dataset_download(\"birdy654/cifake-real-and-ai-generated-synthetic-images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdW7JJ--0sRd"
      },
      "outputs": [],
      "source": [
        "train_path = f\"{path}/cifake/train\"\n",
        "test_path = f\"{path}/cifake/test\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pré-processamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAZ77o-Q1KLR"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_data = datasets.ImageFolder(root=\"../data/train\", transform=transform)\n",
        "test_data = datasets.ImageFolder(root=\"../data/test\", transform=transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXt9nU5q290R"
      },
      "source": [
        "### Divisão Holdout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hESJdappA1hy"
      },
      "outputs": [],
      "source": [
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
        "train_idx, val_idx = next(split.split(np.zeros(len(train_data.targets)), train_data.targets))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Gt4QMw20BFsL"
      },
      "outputs": [],
      "source": [
        "train_split = Subset(train_data, train_idx)\n",
        "val_split = Subset(train_data, val_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dqYVZurBKc-",
        "outputId": "abcc8eab-e7f5-48e7-8276-b8afe804a0cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Treino: 70000 imagens\n",
            "Validação: 30000 imagens\n",
            "Teste: 20000 imagens\n"
          ]
        }
      ],
      "source": [
        "print(f\"Treino: {len(train_split)} imagens\")\n",
        "print(f\"Validação: {len(val_split)} imagens\")\n",
        "print(f\"Teste: {len(test_data)} imagens\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_labels = [label for _, label in train_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_X_y(dataset):\n",
        "    X = []\n",
        "    y = []\n",
        "    for img, label in dataset:\n",
        "        X.append(img.numpy())  \n",
        "        y.append(label)\n",
        "    X = np.stack(X)\n",
        "    y = np.array(y)\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, y_train = get_X_y(train_split)\n",
        "X_val, y_val = get_X_y(val_split)\n",
        "X_test, y_test = get_X_y(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = \"GPU\" if tf.config.list_physical_devices('GPU') else \"CPU\"\n",
        "print(\"Usando:\", device)\n",
        "\n",
        "def preprocess_keras(X):\n",
        "    # transpor de (N, C, H, W) -> (N, H, W, C)\n",
        "    X = np.transpose(X, (0, 2, 3, 1))\n",
        "    X = preprocess_input(X.astype(np.float32))  # normalização ResNet50\n",
        "    return X\n",
        "\n",
        "X_train_keras = preprocess_keras(X_train)\n",
        "X_val_keras = preprocess_keras(X_val)\n",
        "X_test_keras = preprocess_keras(X_test)\n",
        "\n",
        "\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False  # pra transfer Learning congela base\n",
        "\n",
        "\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_keras, y_train,\n",
        "    validation_data=(X_val_keras, y_val),\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    verbose=3\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_prob = model.predict(X_test_keras).ravel()\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\n",
        "plt.xlabel(\"Predito\")\n",
        "plt.ylabel(\"Real\")\n",
        "plt.title(\"Matriz de Confusão\")\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification_report(y_test, y_pred, target_names=[\"Real\", \"Fake\"]))\n",
        "\n",
        "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
        "print(f\"AUC (ROC): {roc_auc:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(history.history['accuracy'], label='Treino')\n",
        "plt.plot(history.history['val_accuracy'], label='Validação')\n",
        "plt.title(\"Acurácia\")\n",
        "plt.xlabel(\"Época\")\n",
        "plt.ylabel(\"Acurácia\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
